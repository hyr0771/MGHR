# ğŸ¯ è¶…å‚æ•°è°ƒä¼˜æŒ‡å—

## ğŸ“Š è¶…å‚æ•°åˆ†ç±»

### ğŸš€ è®­ç»ƒåŸºç¡€å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | ç±»å‹ | è¯´æ˜ | è°ƒä¼˜å»ºè®® |
|------|--------|------|------|----------|
| `--epochs` | 20 | int | è®­ç»ƒè½®æ•° | 10-50ï¼Œæ ¹æ®æ”¶æ•›æƒ…å†µè°ƒæ•´ |
| `--lr` | 2.8e-4 | float | ä¸»å­¦ä¹ ç‡ | 1e-4 åˆ° 5e-4 |
| `--xvlm_lr` | 5e-5 | float | XVLMå­¦ä¹ ç‡ | 1e-5 åˆ° 1e-4 |
| `--batch_size` | 32 | int | æ‰¹å¤„ç†å¤§å° | 16-64ï¼Œæ ¹æ®GPUå†…å­˜è°ƒæ•´ |
| `--update_freq` | 4 | int | å‚æ•°æ›´æ–°é¢‘ç‡ | 2-8ï¼Œå½±å“æœ‰æ•ˆæ‰¹å¤§å° |
| `--seed` | 1204 | int | éšæœºç§å­ | ç¡®ä¿å®éªŒå¯é‡ç° |

### ğŸ§  æ¨¡å‹æ¶æ„å‚æ•°

#### BAN (Bilinear Attention Networks)
| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ | è°ƒä¼˜å»ºè®® |
|------|--------|------|----------|
| `--gamma` | 2 | glimpseæ•°é‡ | 1-4ï¼Œå½±å“æ³¨æ„åŠ›æœºåˆ¶ |
| `--use_counter` | False | æ˜¯å¦ä½¿ç”¨è®¡æ•°å™¨æ¨¡å— | æ ¹æ®ä»»åŠ¡éœ€è¦å¼€å¯ |
| `--counter_act` | 'zhang' | è®¡æ•°å™¨æ¿€æ´»å‡½æ•° | é€šå¸¸ä¿æŒé»˜è®¤ |

#### AOA (Attention on Attention)
| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ | è°ƒä¼˜å»ºè®® |
|------|--------|------|----------|
| `--AOA_layers` | 6 | AOAå±‚æ•° | 4-8ï¼Œå½±å“æ¨¡å‹å¤æ‚åº¦ |
| `--num_hid` | 1024 | è”åˆè¡¨ç¤ºç»´åº¦ | 512-2048ï¼Œå½±å“è¡¨è¾¾èƒ½åŠ› |

#### æ¿€æ´»å‡½æ•°å’Œæ­£åˆ™åŒ–
| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ | è°ƒä¼˜å»ºè®® |
|------|--------|------|----------|
| `--activation` | 'swish' | æ¿€æ´»å‡½æ•° | 'relu', 'swish' |
| `--dropout` | 0.45 | Dropoutç‡ | 0.3-0.6ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ |

### ğŸ” æ•°æ®å¤„ç†å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ | è°ƒä¼˜å»ºè®® |
|------|--------|------|----------|
| `--question_len` | 12 | é—®é¢˜æœ€å¤§é•¿åº¦ | 8-20ï¼Œæ ¹æ®é—®é¢˜å¤æ‚åº¦ |
| `--max_boxes` | 50 | æœ€å¤§è¾¹ç•Œæ¡†æ•°é‡ | 30-100ï¼Œæ ¹æ®å›¾åƒå¤æ‚åº¦ |
| `--num_stat_word` | 30 | ç»Ÿè®¡è¯æ•°é‡ | 20-50 |
| `--tfidf` | True | æ˜¯å¦ä½¿ç”¨TF-IDF | é€šå¸¸ä¿æŒTrue |

### ğŸ¯ ISubGVQAç‰¹å®šå‚æ•°

#### å›¾ç¥ç»ç½‘ç»œå‚æ•°
| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ | è°ƒä¼˜å»ºè®® |
|------|--------|------|----------|
| `--general_hidden_dim` | 300 | éšè—å±‚ç»´åº¦ | 256-512 |
| `--mgat_layers` | 4 | MGATå±‚æ•° | 2-6 |
| `--sampler_type` | 'imle' | é‡‡æ ·å™¨ç±»å‹ | 'imle', 'gumbel' |
| `--sample_k` | 2 | é‡‡æ ·Kå€¼ | 1-5 |
| `--nb_samples` | 1 | æ ·æœ¬æ•°é‡ | 1-3 |

#### æ§åˆ¶å‚æ•°
| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ | è°ƒä¼˜å»ºè®® |
|------|--------|------|----------|
| `--alpha` | 1.0 | Alphaå‚æ•° | 0.5-2.0 |
| `--beta` | 10.0 | Betaå‚æ•° | 5.0-20.0 |
| `--tau` | 1.0 | Tauå‚æ•° | 0.5-2.0 |
| `--use_instruction` | 1 | æ˜¯å¦ä½¿ç”¨æŒ‡ä»¤ | 0/1 |
| `--use_masking` | 1 | æ˜¯å¦ä½¿ç”¨æ©ç  | 0/1 |
| `--use_mgat` | 0 | æ˜¯å¦ä½¿ç”¨MGAT | 0/1 |

### ğŸ”§ ä¼˜åŒ–å‚æ•°

#### æ¢¯åº¦ç›¸å…³
| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ | è°ƒä¼˜å»ºè®® |
|------|--------|------|----------|
| `--clip_norm` | 0.25 | æ¢¯åº¦è£å‰ªé˜ˆå€¼ | 0.1-0.5 |
| `--gradient_accumulation_steps` | 1 | æ¢¯åº¦ç´¯ç§¯æ­¥æ•° | 1-8ï¼Œæ¨¡æ‹Ÿæ›´å¤§æ‰¹å¤§å° |

#### å†…å­˜ä¼˜åŒ–
| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ | è°ƒä¼˜å»ºè®® |
|------|--------|------|----------|
| `--dynamic_batch_size` | False | åŠ¨æ€æ‰¹å¤§å° | å†…å­˜ä¸è¶³æ—¶å¼€å¯ |
| `--max_memory_usage` | 0.8 | æœ€å¤§å†…å­˜ä½¿ç”¨ç‡ | 0.7-0.9 |
| `--mixed_precision` | False | æ··åˆç²¾åº¦è®­ç»ƒ | é€šå¸¸å¼€å¯ä»¥èŠ‚çœå†…å­˜ |
| `--memory_efficient_attention` | False | å†…å­˜é«˜æ•ˆæ³¨æ„åŠ› | å†…å­˜ä¸è¶³æ—¶å¼€å¯ |

### ğŸ›ï¸ å¾®è°ƒå‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ | è°ƒä¼˜å»ºè®® |
|------|--------|------|----------|
| `--omega_q` | 0.1 | é—®é¢˜æŒ‡ä»¤æƒé‡ | 0.05-0.2 |
| `--omega_v` | 0.01 | å›¾åƒè¯­ä¹‰æƒé‡ | 0.005-0.05 |
| `--fusion_ratio` | 0.1 | èåˆæ¯”ä¾‹ | 0.05-0.2 |
| `--topk` | 6 | Top-Kå€¼ | 3-10 |

## ğŸ¯ è°ƒä¼˜ç­–ç•¥

### 1. åŸºç¡€è°ƒä¼˜æµç¨‹

```bash
# ç¬¬ä¸€æ­¥ï¼šè°ƒæ•´å­¦ä¹ ç‡å’Œæ‰¹å¤§å°
python main.py \
  --lr 2.8e-4 \
  --xvlm_lr 5e-5 \
  --batch_size 32 \
  --epochs 20

# ç¬¬äºŒæ­¥ï¼šè°ƒæ•´æ¨¡å‹å¤æ‚åº¦
python main.py \
  --AOA_layers 6 \
  --num_hid 1024 \
  --dropout 0.45

# ç¬¬ä¸‰æ­¥ï¼šè°ƒæ•´ISubGVQAå‚æ•°
python main.py \
  --general_hidden_dim 300 \
  --mgat_layers 4 \
  --alpha 1.0 \
  --beta 10.0
```

### 2. å†…å­˜ä¼˜åŒ–è°ƒä¼˜

```bash
# å†…å­˜ä¸è¶³æ—¶çš„é…ç½®
python main.py \
  --batch_size 16 \
  --gradient_accumulation_steps 2 \
  --mixed_precision \
  --memory_efficient_attention \
  --max_memory_usage 0.7
```

### 3. æ€§èƒ½ä¼˜åŒ–è°ƒä¼˜

```bash
# é«˜æ€§èƒ½é…ç½®
python main.py \
  --batch_size 64 \
  --update_freq 2 \
  --dynamic_batch_size \
  --max_memory_usage 0.9
```

## ğŸ“ˆ è°ƒä¼˜å»ºè®®

### ğŸ¯ æŒ‰ä»»åŠ¡ç±»å‹è°ƒä¼˜

#### GQAæ•°æ®é›†
```bash
python main.py \
  --dataset GQA \
  --lr 2.8e-4 \
  --batch_size 32 \
  --AOA_layers 6 \
  --general_hidden_dim 300 \
  --mgat_layers 4
```

#### VQAæ•°æ®é›†
```bash
python main.py \
  --dataset VQA \
  --lr 3e-4 \
  --batch_size 24 \
  --AOA_layers 8 \
  --general_hidden_dim 512 \
  --mgat_layers 6
```

### ğŸ” æŒ‰ç¡¬ä»¶é…ç½®è°ƒä¼˜

#### 8GB GPU
```bash
python main.py \
  --batch_size 16 \
  --gradient_accumulation_steps 4 \
  --mixed_precision \
  --max_memory_usage 0.7
```

#### 24GB GPU
```bash
python main.py \
  --batch_size 48 \
  --gradient_accumulation_steps 1 \
  --max_memory_usage 0.9
```

## ğŸ§ª å®éªŒè®¾è®¡

### 1. å­¦ä¹ ç‡å®éªŒ
```bash
# å®éªŒ1ï¼šåŸºç¡€å­¦ä¹ ç‡
python main.py --lr 2.8e-4 --xvlm_lr 5e-5

# å®éªŒ2ï¼šè¾ƒé«˜å­¦ä¹ ç‡
python main.py --lr 3.5e-4 --xvlm_lr 7e-5

# å®éªŒ3ï¼šè¾ƒä½å­¦ä¹ ç‡
python main.py --lr 2e-4 --xvlm_lr 3e-5
```

### 2. æ¨¡å‹å¤æ‚åº¦å®éªŒ
```bash
# å®éªŒ1ï¼šç®€å•æ¨¡å‹
python main.py --AOA_layers 4 --num_hid 512

# å®éªŒ2ï¼šä¸­ç­‰æ¨¡å‹
python main.py --AOA_layers 6 --num_hid 1024

# å®éªŒ3ï¼šå¤æ‚æ¨¡å‹
python main.py --AOA_layers 8 --num_hid 2048
```

### 3. ISubGVQAå‚æ•°å®éªŒ
```bash
# å®éªŒ1ï¼šåŸºç¡€é…ç½®
python main.py --mgat_layers 4 --alpha 1.0 --beta 10.0

# å®éªŒ2ï¼šå¢å¼ºé…ç½®
python main.py --mgat_layers 6 --alpha 1.5 --beta 15.0

# å®éªŒ3ï¼šä¿å®ˆé…ç½®
python main.py --mgat_layers 3 --alpha 0.8 --beta 8.0
```

## ğŸ“Š ç›‘æ§æŒ‡æ ‡

### è®­ç»ƒæŒ‡æ ‡
- è®­ç»ƒæŸå¤±ä¸‹é™è¶‹åŠ¿
- éªŒè¯å‡†ç¡®ç‡
- GPUå†…å­˜ä½¿ç”¨ç‡
- è®­ç»ƒé€Ÿåº¦ï¼ˆæ ·æœ¬/ç§’ï¼‰

### è°ƒä¼˜æ£€æŸ¥ç‚¹
1. **æ”¶æ•›æ€§**ï¼šæŸå¤±æ˜¯å¦ç¨³å®šä¸‹é™
2. **è¿‡æ‹Ÿåˆ**ï¼šéªŒè¯é›†æ€§èƒ½æ˜¯å¦ä¸‹é™
3. **å†…å­˜ä½¿ç”¨**ï¼šæ˜¯å¦å‡ºç°OOMé”™è¯¯
4. **è®­ç»ƒé€Ÿåº¦**ï¼šæ˜¯å¦è¾¾åˆ°é¢„æœŸé€Ÿåº¦

## ğŸ¯ æœ€ä½³å®è·µ

1. **æ¸è¿›å¼è°ƒä¼˜**ï¼šä¸€æ¬¡åªè°ƒæ•´ä¸€ä¸ªå‚æ•°
2. **è®°å½•å®éªŒ**ï¼šä¿å­˜æ¯æ¬¡å®éªŒçš„é…ç½®å’Œç»“æœ
3. **æ—©åœæœºåˆ¶**ï¼šè®¾ç½®åˆç†çš„æ—©åœæ¡ä»¶
4. **äº¤å‰éªŒè¯**ï¼šä½¿ç”¨ä¸åŒçš„éšæœºç§å­éªŒè¯
5. **èµ„æºç›‘æ§**ï¼šå®æ—¶ç›‘æ§GPUå’Œå†…å­˜ä½¿ç”¨

## ğŸ“ ç¤ºä¾‹é…ç½®

### é«˜æ€§èƒ½é…ç½®
```bash
python main.py \
  --checkpoint pretrained/model \
  --config xvlm/configs/VQA_480.yaml \
  --output saved_models/high_performance \
  --lr 3e-4 \
  --xvlm_lr 6e-5 \
  --batch_size 48 \
  --AOA_layers 8 \
  --num_hid 1536 \
  --general_hidden_dim 512 \
  --mgat_layers 6 \
  --alpha 1.2 \
  --beta 12.0 \
  --mixed_precision \
  --max_memory_usage 0.9
```

### å†…å­˜ä¼˜åŒ–é…ç½®
```bash
python main.py \
  --checkpoint pretrained/model \
  --config xvlm/configs/VQA_480.yaml \
  --output saved_models/memory_optimized \
  --lr 2.5e-4 \
  --xvlm_lr 4e-5 \
  --batch_size 16 \
  --gradient_accumulation_steps 4 \
  --AOA_layers 4 \
  --num_hid 768 \
  --general_hidden_dim 256 \
  --mgat_layers 3 \
  --alpha 0.8 \
  --beta 8.0 \
  --mixed_precision \
  --memory_efficient_attention \
  --max_memory_usage 0.7
```

ç°åœ¨ä½ å¯ä»¥æ ¹æ®è¿™ä¸ªæŒ‡å—ç³»ç»Ÿåœ°è°ƒæ•´è¶…å‚æ•°äº†ï¼å»ºè®®ä»åŸºç¡€å‚æ•°å¼€å§‹ï¼Œé€æ­¥è°ƒæ•´åˆ°æ›´å¤æ‚çš„å‚æ•°ã€‚ 