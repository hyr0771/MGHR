"""
This code is modified from Hengyuan Hu's repository.
https://github.com/hengyuan-hu/bottom-up-attention-vqa
"""
import sys
import os
import argparse
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, ConcatDataset
from src.FFOE.dataset import Dictionary, GQAFeatureDataset ,VQAFeatureDataset
import src.FFOE.base_model as base_model
from src.FFOE.train import train,evaluate
import src.utils as utils

# å¯¼å…¥ä¼˜åŒ–çš„æ•°æ®å¤„ç†æ¨¡å—
from src.FFOE.optimized_collate import (
    compatible_collate_fn,
    monitored_compatible_collate_fn
)
import random
import numpy as np
import gc
import psutil

import ruamel.yaml as yaml
from xvlm.dataset import create_dataset, create_sampler, create_loader, vqa_collate_fn
from PIL import Image
from torchvision import transforms
import xvlm.utils as xvlm_utils
# from xvlm.utils.checkpointer import Checkpointer
# from xvlm.utils.hdfs_io import hmkdir, hexists
try:
    import _pickle as pickle
except:
    import pickle

torch._dynamo.config.cache_size_limit = 1024  # é»˜è®¤å€¼è¾ƒå°ï¼Œå¢å¤§åˆ°1024

def memory_cleanup():
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()


def parse_args():
    parser = argparse.ArgumentParser()
    # MODIFIABLE CFRF HYPER-PARAMETERS------------------------------------------------------------------------------
    # Model loading/saving
    parser.add_argument('--input', type=str, default=None,
                        help='input file directory for continue training from stop one')
    # parser.add_argument('--output', type=str, default='saved_models/GQA',
    #                     help='save file directory')
    parser.add_argument('--output', type=str, default='saved_models/GQA/replicate_result_default',
                        help='save file directory')


    # Utilities
    parser.add_argument('--seed', type=int, default=1204,help='random seed')
    parser.add_argument('--epochs', type=int, default=20,help='the number of epoches')
    parser.add_argument('--lr', default=2.8e-4, type=float, metavar='lr',help='initial learning rate')


    # Gradient accumulation
    parser.add_argument('--batch_size', type=int, default=32,help='batch size')
    parser.add_argument('--update_freq', default='4', metavar='N',help='update parameters every n batches in an epoch')


    # Data
    parser.add_argument('--use_both', action='store_true',help='use both train/val datasets to train?')


    # Choices of models
    parser.add_argument('--model', type=str, default='CFRF_Model', choices=['CFRF_Model'],
                        help='the model we use')
    parser.add_argument('--dataset', type=str, default='GQA', choices=['GQA','VQA'],
                        help='Dataset to train and evaluate')

    # INTERACTION LEARNING COMPONENTS HYPER-PARAMETERS------------------------------------------------------------------
    # BAN
    parser.add_argument('--gamma', type=int, default=2,
                        help='glimpse in Bilinear Attention Networks')
    parser.add_argument('--use_counter', action='store_true', default=False,
                        help='use counter module')
    parser.add_argument('--counter_act', type=str, default='zhang', choices=['zhang'],
                        help='the counter activation')


    # CONSTANT HYPER-PARAMETERS (Advanced hyper-params for testing, experimenting or fine-tuning)------------------------
    # Utilities - support testing, gpu training or sampling
    parser.add_argument('--testing', action='store_true', default=False,
                        help='for fast testing 1 epoch')
    parser.add_argument('--print_interval', default=200, type=int, metavar='N',
                        help='print per certain number of steps')
    parser.add_argument('--gpu', type=int, default=0,
                        help='specify index of GPU using for training, to use CPU: -1')
    parser.add_argument('--clip_norm', default=.25, type=float, metavar='NORM',
                        help='clip threshold of gradients')
    parser.add_argument('--weight_init', type=str, default='none', choices=['none', 'kaiming_normal'],
                        help='dynamic weighting with Kaiming normalization')

    # Bounding box set
    parser.add_argument('--max_boxes', default=50, type=int, metavar='N',
                        help='number of maximum bounding boxes for K-adaptive')
    # Stat word
    parser.add_argument('--num_stat_word', default=30, type=int, metavar='N',
                        help='number of statistical word')

    # Question embedding
    parser.add_argument('--question_len', default=12, type=int, metavar='N',
                        help='maximum length of input question')
    parser.add_argument('--tfidf', type=bool, default=True,
                        help='tfidf word embedding?')
    parser.add_argument('--op', type=str, default='c',
                        help='concatenated 600-D word embedding')

    # Joint representation C dimension
    parser.add_argument('--num_hid', type=int, default=1024,
                        help='dim of joint semantic features')

    # Framework hyper-params
    parser.add_argument('--activation', type=str, default='swish', choices=['relu', 'swish'],
                        help='the activation to use for final classifier')
    parser.add_argument('--dropout', default=0.45, type=float, metavar='dropout',
                        help='dropout of rate of final classifier')

    # Debugging
    parser.add_argument("--fast", action='store_const', default=False, const=True)
    parser.add_argument("--tiny", action='store_const', default=False, const=True)
    parser.add_argument("--tqdm", action='store_const', default=False, const=True)

    # Model Loading
    parser.add_argument('--load', type=str, default=None,
                        help='Load the model (usually the fine-tuned model).')
    # ç§»é™¤æœªä½¿ç”¨çš„ LXMERT ç›¸å…³å‚æ•°


    # Optimization
    # ç§»é™¤æœªä½¿ç”¨çš„ mceLoss
    # parser.add_argument('--lxmert_lr', default=5e-5, type=float, metavar='lr',
    #                     help='initial learning rate')
    parser.add_argument('--xvlm_lr', default=5e-5, type=float, metavar='lr',
                        help='initial learning rate')


    # LXRT Model Config
    # Note: LXRT = L, X, R (three encoders), Transformer
    # parser.add_argument("--llayers", default=9, type=int, help='Number of Language layers')
    # ç§»é™¤ä¸ LXMERT é…ç½®ç›¸å…³çš„å¤šä½™å±‚æ•°å‚æ•°

    # LXMERT Pre-training Config
    # ç§»é™¤ LXMERT é¢„è®­ç»ƒç›¸å…³ä»»åŠ¡å¼€å…³

    # Training configuration
    # ç§»é™¤æ—§çš„ multiGPU æ ‡å¿—ï¼ˆæ”¹ç”¨ --distributed + torchrunï¼‰
    # parser.add_argument("--numWorkers", dest='num_workers', default=8)

    # Fine-tuning arguments
    parser.add_argument('--omega_q', type=float, default=0.1,
                        help='omega for control the effect of question instructions')
    parser.add_argument('--omega_v', type=float, default=0.01,
                        help='omega for control the effect of image semantics')
    parser.add_argument('--fusion_ratio', type=float, default=0.1,
                        help='ratio for control the effect of adapted weight')

    parser.add_argument('--topk', default='6', type=int)

    # Modal interaction hyperparameters
    parser.add_argument('--AOA_layers', type=int, default=6,
                        help='The number of layers of the AOA')

    #XVLM
    parser.add_argument('--checkpoint', type=str, required=True)
    parser.add_argument('--config', default='./xvlm/configs/VQA_480.yaml')
    parser.add_argument('--output_dir', default='output/vqa')
    parser.add_argument('--output_hdfs', type=str, default='', help="to collect eval results among nodes")

    parser.add_argument('--device', default='cuda')
    parser.add_argument('--xvlm_seed', default=42, type=int)
    parser.add_argument('--world_size', default=1, type=int, help='number of distributed processes')
    parser.add_argument('--dist_url', default='env://', help='url used to set up distributed training')
    # parser.add_argument('--distributed', action='store_false')

    parser.add_argument('--bs', default=-1, type=int)
    parser.add_argument('--evaluate', action='store_true')

    #ISubGVQA
    parser.add_argument("--general_hidden_dim", type=int, default=300)
    parser.add_argument("--distributed", action="store_true", default=False)
    parser.add_argument("--use_all_instrs", action="store_true", default=False)
    parser.add_argument("--use_global_mask", action="store_true", default=False)
    parser.add_argument("--node_classification", action="store_true", default=False)
    parser.add_argument("--sampler_type", type=str,default="imle")
    parser.add_argument("--sample_k", type=int, default=2)
    parser.add_argument("--nb_samples", default=1, type=int, metavar="N")
    parser.add_argument("--alpha", default=1.0, type=float)
    parser.add_argument("--beta", default=10.0, type=float)
    parser.add_argument("--tau", default=1.0, type=float)

    parser.add_argument("--gnn_gating", type=int, default=1)
    parser.add_argument("--use_instruction", type=int, default=1)
    parser.add_argument("--use_masking", type=int, default=1)
    parser.add_argument("--use_mgat", type=int, default=0)
    parser.add_argument("--mgat_masks", nargs="+", type=float, default=[1.0, 1.0, 1.0, 0.15])

    parser.add_argument("--use_topk", type=int, default=True)
    parser.add_argument("--interpretable_mode", type=int, default=False)
    parser.add_argument("--experiment_name", type=str)
    parser.add_argument("--concat_instr", type=int, default=0)
    parser.add_argument("--embed_cat", type=int, default=0)
    parser.add_argument("--text_sampling", action="store_true", default=False)
    parser.add_argument("--mgat_layers", default=4, type=int, metavar="N")
    parser.add_argument("--clip_url", default='/home/hjm/.cache/huggingface/transformers/openai/clip-vit-base-patch32/')
    
    # å†…å­˜ä¼˜åŒ–å‚æ•°
    # ç²¾ç®€ï¼šå¤šå¡ä¸‹é»˜è®¤å…³é—­åŠ¨æ€æ‰¹/æ··åˆç²¾åº¦/å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›ç­‰å‚æ•°ï¼Œå¯æŒ‰éœ€æ¢å¤
    parser.add_argument('--dry-run', action='store_true', help='ä»…åŠ è½½æ¨¡å—ï¼Œä¸æ‰§è¡Œè®­ç»ƒ')
    # XVLM å¾®è°ƒ/è’¸é¦ç›¸å…³
    parser.add_argument('--tune_xvlm', action='store_true', default=False,
                        help='å¾®è°ƒ XVLMï¼šè®­ç»ƒä¸­å¯¹ XVLM æ¦‚ç‡è®¡ç®—ä¿ç•™æ¢¯åº¦ï¼Œå¹¶å¼•å…¥ XVLM çš„ BCE åˆ†ç±»æŸå¤±')
    parser.add_argument('--lambda_xvlm', type=float, default=0.3,
                        help='XVLM BCE æŸå¤±åœ¨æ€»æŸå¤±ä¸­çš„æƒé‡ï¼ˆä»…å½“ --tune_xvlm æ—¶ç”Ÿæ•ˆï¼‰')

    # è°ƒè¯•/ç¨³å®šæ€§å¼€å…³ï¼ˆDDP æ•…éšœæ’æŸ¥ï¼‰
    parser.add_argument('--mixed_precision', action='store_true', default=False,
                        help='å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆAMPï¼‰ï¼Œé™ä½æ˜¾å­˜å ç”¨ã€æå‡è®­ç»ƒé€Ÿåº¦')
    parser.add_argument('--disable_syncbn', action='store_true', default=False,
                        help='ç¦ç”¨ SyncBatchNormï¼ˆç”¨ BatchNorm1d æ›¿ä»£ï¼‰ï¼Œç”¨äºæ’æŸ¥å¤šå¡å¡æ­»/ä¸åŒæ­¥é—®é¢˜')
    parser.add_argument('--dataloader_single_worker', action='store_true', default=False,
                        help='å°† DataLoader è®¾ä¸ºå• workerï¼ˆnum_workers=0, persistent_workers=Falseï¼‰ä»¥æ’æŸ¥æ•°æ®åŠ è½½é—®é¢˜')
    parser.add_argument('--train_drop_last', action='store_true', default=False,
                        help='è®­ç»ƒ DataLoader ä¸¢å¼ƒæœ€åä¸å®Œæ•´ batchï¼ˆå¤šå¡å»ºè®®å¼€å¯ï¼Œé¿å…ä¸åŒæ­¥ï¼‰')
    parser.add_argument('--debug_log_steps', action='store_true', default=False,
                        help='æ‰“å°æ¯ä¸ª rank çš„ step å¯¹é½æ—¥å¿—ï¼Œå¸®åŠ©å®šä½å¡ä½æ­¥æ•°')
    parser.add_argument('--barrier_each_step', action='store_true', default=False,
                        help='æ¯ä¸ªè®­ç»ƒ step æœ«å°¾åŠ ä¸€æ¬¡ dist.barrier()ï¼ˆä»…è°ƒè¯•ç”¨ï¼Œä¼šæ˜¾è‘—é™é€Ÿï¼‰')

    # DDP æ€§èƒ½/æ”¶æ•›å¼€å…³
    parser.add_argument('--strict_ddp', action='store_true', default=False,
                        help='å¯ç”¨ä¸¥æ ¼ DDPï¼ˆfind_unused_parameters=Falseï¼‰ï¼Œè¦æ±‚æ‰€æœ‰å‚æ•°æ¯æ­¥éƒ½å‚ä¸è®¡ç®—')
    parser.add_argument('--ddp_bucket_cap_mb', type=int, default=100,
                        help='DDP æ¢¯åº¦æ¡¶å¤§å°ï¼ˆMBï¼‰ï¼Œæ›´å¤§å¯å‡å°‘ allreduce æ¬¡æ•°ï¼Œé»˜è®¤100MB')

    # Return args
    args = parser.parse_args()
    return args


if __name__ == '__main__':
    args = parse_args()

    # ï¼ˆå·²ç§»é™¤ï¼‰å¤–éƒ¨ä¼˜åŒ–é…ç½®åŠ è½½ä¸åº”ç”¨ï¼ŒDDP è®­ç»ƒä¸ä¾èµ–è¯¥æœºåˆ¶
    
    #XVLM
    config = yaml.load(open(args.config, 'r'), Loader=yaml.Loader)
    xvlm_utils.init_distributed_mode(args)  # åˆå§‹åŒ–åˆ†å¸ƒå¼è®­ç»ƒæ¨¡å¼ï¼ˆä¼šåœ¨åˆ†å¸ƒå¼æ—¶è®¾ç½® args.gpu å¹¶ç»‘å®šè®¾å¤‡ï¼‰
    # ç¡®ä¿æ—¥å¿—åŠæ—¶åˆ·æ–°ï¼ˆå¤šè¿›ç¨‹ä¸‹ä¾¿äºè§‚å¯Ÿ rank è¾“å‡ºï¼‰
    try:
        sys.stdout.reconfigure(line_buffering=True)
    except Exception:
        pass
    
    # å¦‚é€šè¿‡ CLI è¯·æ±‚ç¦ç”¨ SyncBatchNormï¼Œåˆ™è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œåº•å±‚åœºæ™¯å›¾æ¨¡å—ä¼šè¯»å–
    if getattr(args, 'disable_syncbn', False):
        os.environ['DISABLE_SYNCBN'] = '1'
    # åˆ†å¸ƒå¼æ—¶æŒ‰æœ¬åœ°rankç»‘å®šè®¾å¤‡ï¼›å¦åˆ™æŒ‰ç”¨æˆ·æŒ‡å®šçš„ device
    if getattr(args, 'distributed', False):
        device = torch.device(f"cuda:{args.gpu}")
    else:
        device = torch.device(args.device)
    args.device = device
    world_size = xvlm_utils.get_world_size()  # å•æœºå¤šå¡ï¼šworld_sizeä»£è¡¨æœ‰å‡ å—GPU
    if getattr(args, 'distributed', False):
        try:
            import torch.distributed as dist
            if dist.is_available() and dist.is_initialized():
                print(f"[rank={dist.get_rank()}] world_size={world_size} device={device}")
        except Exception:
            pass

    # if world_size > 8:  # å¦‚æœè¿›ç¨‹æ€»æ•°å¤§äº8ï¼Œç¡®ä¿è¾“å‡ºç›®å½•åœ¨HDFSä¸Šï¼Œå¹¶ä¸”HDFSè·¯å¾„çš„æ ¼å¼æ­£ç¡®
    #     assert hexists(args.output_hdfs) and args.output_hdfs.startswith('hdfs'), "for collect_result among nodes"

    if args.bs > 0:  # å¦‚æœå‘½ä»¤è¡Œå‚æ•°ä¸­æŒ‡å®šäº†bsï¼ˆæ‰¹å¤„ç†å¤§å°ï¼‰ï¼Œåˆ™æ›´æ–°é…ç½®ä¸­çš„è®­ç»ƒæ‰¹å¤„ç†å¤§å°ï¼ˆæŒ‰æ€»batché™¤ä»¥å¡æ•°ï¼‰
        config['batch_size_train'] = max(1, args.bs // max(world_size, 1))

    # åŠ¨æ€æ‰¹å¤§å°å·²ç¦ç”¨ï¼ˆDDP ä¸‹ä¸å»ºè®®åœ¨çº¿æ¢æµ‹æ˜¾å­˜ï¼‰

    utils.create_dir(args.output)
    logger = utils.Logger(os.path.join(args.output, 'log.txt')) #æ—¥å¿—åœ°å€
    logger.write(args.__repr__())

    # device = torch.device("cuda:" + str(args.gpu) if args.gpu >= 0 else "cpu")
    # args.device = device

    #è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å®éªŒçš„å¯é‡å¤æ€§ï¼Œå¹¶é…ç½® CUDA åŠ é€Ÿåº“ä»¥æå‡æ€§èƒ½ã€‚åŒæ—¶è®¾ç½®å½“å‰ CUDA è®¾å¤‡ä¸º args.gpu æŒ‡å®šçš„ GPUã€‚
    args.seed = args.seed + xvlm_utils.get_rank()  # è®¾ç½®éšæœºç§å­ï¼Œä»¥ç¡®ä¿å®éªŒå¯é‡å¤
    torch.manual_seed(args.seed)
    torch.cuda.manual_seed(args.seed)
    np.random.seed(args.seed)   #XVLM
    random.seed(args.seed)  #XVLM
    torch.backends.cudnn.benchmark = True
    # torch.cuda.set_device(args.gpu)

    #XVLM
    normalize = transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))
    transform = transforms.Compose([
        transforms.Resize((config['image_res'], config['image_res']), interpolation=Image.BICUBIC),
        transforms.ToTensor(),
        normalize,
    ])

    # å¦‚æœ args.dataset æ˜¯ 'GQA'ï¼Œåˆ™ä»æ–‡ä»¶ 'data/gqa/dictionary.pkl' ä¸­åŠ è½½è¯å…¸ dictionaryï¼Œ
    # å¹¶åˆå§‹åŒ–è®­ç»ƒé›† train_dset å’ŒéªŒè¯é›† val_dsetã€‚
    if args.dataset == 'GQA':
        dictionary = Dictionary.load_from_file('data/gqa/dictionary.pkl')   #è¿™ä¸ªè¯å…¸æ–‡ä»¶é€šå¸¸åŒ…å«äº†æ•°æ®é›†ä¸­å‡ºç°çš„æ‰€æœ‰è¯æ±‡ï¼Œæ¯”å¦‚å¯¹è±¡åç§°ã€å±æ€§æè¿°ç­‰
        train_dset = GQAFeatureDataset(args, 'train', dictionary, adaptive=True,
                                       ann_file=config['train_file'], transform=transform,
                                       gqa_image_root=config['gqa_root'],
                                       gqa_answer_list=config['answer_list'], text_encoder=config['text_encoder'])  # XVLM
        val_dset = GQAFeatureDataset(args, 'val', dictionary, adaptive=True,
                                     ann_file=config['train_file'], transform=transform,
                                     gqa_image_root=config['gqa_root'],
                                     gqa_answer_list=config['answer_list'], text_encoder=config['text_encoder'])
    elif args.dataset == 'VQA':
        dictionary = Dictionary.load_from_file('data/vqa/dictionary.pkl')
        train_dset = VQAFeatureDataset(args,'train', dictionary, adaptive=True,
                                       ann_file=config['train_file'],transform=transform,vqa_image_root=config['vqa_root'],
                                       vg_image_root=config['vg_root'],
                                       answer_list=config['answer_list'],text_encoder=config['text_encoder'])   #XVLM
        val_dset = VQAFeatureDataset(args,'val', dictionary, adaptive=True,
                                     ann_file=config['train_file'], transform=transform,vqa_image_root=config['vqa_root'],
                                     vg_image_root= config['vg_root'],
                                     answer_list=config['answer_list'], text_encoder=config['text_encoder'])
    else:
        raise BaseException("Dataset name not found!")

    config['pad_token_id'] = train_dset.pad_token_id
    config['eos'] = train_dset.eos_token

    #æ ¹æ® args.model åŠ¨æ€æ„å»ºæ¨¡å‹æ„é€ å‡½æ•°çš„åç§° constructorï¼Œ
    # ç„¶åé€šè¿‡ getattr å‡½æ•°ä» base_model æ¨¡å—ä¸­è·å–ç›¸åº”çš„æ¨¡å‹æ„é€ å‡½æ•°ï¼Œ
    # å¹¶ä½¿ç”¨ train_dset å’Œ args åˆå§‹åŒ–æ¨¡å‹ modelã€‚
    # å°†æ¨¡å‹ç§»åŠ¨åˆ°æŒ‡å®šçš„è®¾å¤‡ device ä¸Šã€‚
    batch_size = args.batch_size
    constructor = 'build_%s' % args.model
    model = getattr(base_model, constructor)(train_dset, args,config)
    model = model.to(device)


    if args.distributed:  # å¦‚æœæ˜¯åˆ†å¸ƒå¼è®­ç»ƒï¼ŒåŒ…è£…æ¨¡å‹ä»¥æ”¯æŒåˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œ
        # å…³é—­ broadcast_buffers å¯å‡å°‘ BN buffer åŒæ­¥å¼•å‘çš„ä¸ä¸€è‡´
        ddp_kwargs = dict(
            device_ids=[args.gpu],
            broadcast_buffers=False,
            bucket_cap_mb=getattr(args, 'ddp_bucket_cap_mb', 100)
        )
        # ä¸¥æ ¼ DDPï¼šè¦æ±‚æ‰€æœ‰å‚æ•°å‚ä¸ï¼Œæå‡æ€§èƒ½
        if getattr(args, 'strict_ddp', False):
            ddp_kwargs['find_unused_parameters'] = False
        else:
            ddp_kwargs['find_unused_parameters'] = True
        model = torch.nn.parallel.DistributedDataParallel(model, **ddp_kwargs)

    optim = None
    epoch = 0
    # load snapshot
    #å¦‚æœæŒ‡å®šäº† args.inputï¼Œåˆ™åŠ è½½æ¨¡å‹å¿«ç…§ã€‚ --input:ï¼ˆinput file directory for continue training from stop oneï¼‰
    if args.input is not None:
        if xvlm_utils.is_main_process():
            print(f'ğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹å¿«ç…§: {args.input}')
        
        # ä½¿ç”¨ map_location ç¡®ä¿æ¨¡å‹åŠ è½½åˆ°æ­£ç¡®çš„è®¾å¤‡
        model_data = torch.load(args.input, map_location=device)
        
        # åŠ è½½æ¨¡å‹çŠ¶æ€å­—å…¸
        if 'model_state' in model_data:
            model.load_state_dict(model_data['model_state'])
        else:
            model.load_state_dict(model_data)
        
        # æ›´æ–° epoch ä¿¡æ¯
        epoch = model_data.get('epoch', 0) + 1
        
        # æ¸…ç†åŠ è½½çš„æ¨¡å‹æ•°æ®ï¼Œé‡Šæ”¾å†…å­˜
        del model_data
        memory_cleanup()
        
        if xvlm_utils.is_main_process():
            print(f'âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼Œå°†ä» epoch {epoch} å¼€å§‹ç»§ç»­è®­ç»ƒ')
            print(f'ğŸ’¾ å½“å‰æ˜¾å­˜å ç”¨: {torch.cuda.memory_allocated(device) / 1024**3:.2f} GB')

    #æ ¹æ® args.use_both çš„å€¼ï¼Œå†³å®šå¦‚ä½•è®¾ç½®è®­ç»ƒæ•°æ®åŠ è½½å™¨ train_loader å’Œè¯„ä¼°æ•°æ®åŠ è½½å™¨ eval_loaderã€‚
    # å¦‚æœ args.use_both ä¸ºçœŸï¼Œåˆ™å°†è®­ç»ƒé›†å’ŒéªŒè¯é›†åˆå¹¶ä¸º trainval_dsetï¼Œå¹¶åˆ›å»ºç›¸åº”çš„åŠ è½½å™¨ã€‚å¦åˆ™ï¼Œåˆ†åˆ«åˆ›å»ºè®­ç»ƒé›†å’ŒéªŒè¯é›†çš„åŠ è½½å™¨
    if args.use_both:  # use train & val splits to optimize
        trainval_dset = ConcatDataset([train_dset, val_dset])
        
        # ä½¿ç”¨ä¼˜åŒ–çš„æ‰¹å¤„ç†å‡½æ•°
        if xvlm_utils.is_main_process():
            print("ğŸš€ ä½¿ç”¨ä¼˜åŒ–çš„æ‰¹å¤„ç†å‡½æ•° (compatible_collate_fn)")
        train_loader = DataLoader(
            trainval_dset, 
            batch_size, 
            shuffle=True, 
            num_workers=0, 
            collate_fn=compatible_collate_fn,
            pin_memory=True
        )
        eval_loader = None
        
        # æ¸…ç†åŸå§‹æ•°æ®é›†ï¼Œé‡Šæ”¾å†…å­˜
        del train_dset, val_dset, trainval_dset
        memory_cleanup()
        
        if xvlm_utils.is_main_process():
            print(f'ğŸ’¾ åˆå¹¶æ•°æ®é›† DataLoader åˆ›å»ºå®Œæˆï¼Œå½“å‰æ˜¾å­˜å ç”¨: {torch.cuda.memory_allocated(device) / 1024**3:.2f} GB')
    else:   #å‘½ä»¤è¡Œä¸­ä¸åŠ --use_bothï¼Œé»˜è®¤ä¸ºfalse
        datasets = [train_dset, val_dset]

        if args.distributed:  # å¦‚æœæ˜¯åˆ†å¸ƒå¼è®­ç»ƒï¼Œè·å–åˆ†å¸ƒå¼ç¯å¢ƒçš„è¿›ç¨‹æ•°å’Œå…¨å±€æ’å
            num_tasks = xvlm_utils.get_world_size()  # è·å–åˆ†å¸ƒå¼ç¯å¢ƒä¸­çš„è¿›ç¨‹æ€»æ•°
            global_rank = xvlm_utils.get_rank()  # è·å–å½“å‰è¿›ç¨‹çš„æ’å
            samplers = create_sampler(datasets, [True, True], num_tasks, global_rank)  # åˆ›å»ºåˆ†å¸ƒå¼é‡‡æ ·å™¨
        else:
            samplers = [None, None]  # å¦‚æœä¸æ˜¯åˆ†å¸ƒå¼è®­ç»ƒï¼Œä½¿ç”¨é»˜è®¤çš„Noneé‡‡æ ·å™¨

        train_dataset_size = len(train_dset)  # è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†çš„å¤§å°
        world_size = xvlm_utils.get_world_size()  # è·å–è¿›ç¨‹æ€»æ•°

        if xvlm_utils.is_main_process():     # å¦‚æœæ˜¯ä¸»è¿›ç¨‹ï¼Œæ‰“å°æ•°æ®é›†å¤§å°å’Œæ‰¹å¤„ç†å¤§å°ä¿¡æ¯
            logger.write(f"### data {train_dataset_size}, batch size, {config['batch_size_train']} x {world_size}")
            # print(f"### data {train_dataset_size}, batch size, {config['batch_size_train']} x {world_size}")
        
        # ä¼˜åŒ–æ•°æ®åŠ è½½å™¨é…ç½®ï¼ˆæ”¯æŒå• worker è°ƒè¯•ï¼‰
        if getattr(args, 'dataloader_single_worker', False):
            num_workers = 0
            prefetch_factor = None
            persistent_workers = False
        else:
            num_workers = min(8, os.cpu_count())  # æ ¹æ®CPUæ ¸å¿ƒæ•°è°ƒæ•´workeræ•°é‡
            prefetch_factor = 2  # é¢„å–å› å­
            persistent_workers = True
        
        # é€‰æ‹©ä¼˜åŒ–çš„æ‰¹å¤„ç†å‡½æ•°
        use_monitoring = getattr(args, 'enable_performance_monitoring', False)
        if use_monitoring:
            collate_fn = monitored_compatible_collate_fn
            if xvlm_utils.is_main_process():
                print("ğŸš€ ä½¿ç”¨å¸¦æ€§èƒ½ç›‘æ§çš„ä¼˜åŒ–æ‰¹å¤„ç†å‡½æ•°")
        else:
            collate_fn = compatible_collate_fn
            if xvlm_utils.is_main_process():
                print("ğŸš€ ä½¿ç”¨ä¼˜åŒ–çš„æ‰¹å¤„ç†å‡½æ•°")
        
        # æ„é€ è®­ç»ƒ DataLoader çš„å‚æ•°ï¼Œé¿å…åœ¨å• worker æ¨¡å¼ä¼ å…¥ prefetch_factor/persistent_workers
        train_dl_kwargs = dict(
            dataset=train_dset,
            batch_size=batch_size,
            shuffle=False,
            collate_fn=collate_fn,
            pin_memory=True,
            sampler=samplers[0],
            drop_last=getattr(args, 'train_drop_last', False),
        )
        if num_workers > 0:
            train_dl_kwargs.update(dict(
                num_workers=num_workers,
                prefetch_factor=prefetch_factor,
                persistent_workers=persistent_workers,
            ))
        else:
            train_dl_kwargs.update(dict(num_workers=0))
        train_loader = DataLoader(**train_dl_kwargs)

        # æ„é€ è¯„ä¼° DataLoader çš„å‚æ•°
        eval_dl_kwargs = dict(
            dataset=val_dset,
            batch_size=batch_size,
            shuffle=False,
            collate_fn=collate_fn,
            pin_memory=True,
            sampler=samplers[1],
            drop_last=True,
        )
        if not getattr(args, 'dataloader_single_worker', False) and num_workers > 0:
            eval_dl_kwargs.update(dict(
                num_workers=num_workers,
                prefetch_factor=prefetch_factor,
                persistent_workers=persistent_workers,
            ))
        else:
            eval_dl_kwargs.update(dict(num_workers=0))
        eval_loader = DataLoader(**eval_dl_kwargs)

        # éªŒè¯å„ rank çš„ DataLoader æ­¥æ•°æ˜¯å¦ä¸€è‡´ï¼Œé¿å…ä¸åŒæ­¥
        if getattr(args, 'distributed', False):
            try:
                import torch.distributed as dist
                if dist.is_available() and dist.is_initialized():
                    local_len = torch.tensor([len(train_loader)], device=device)
                    len_max = local_len.clone()
                    len_min = local_len.clone()
                    dist.all_reduce(len_max, op=dist.ReduceOp.MAX)
                    dist.all_reduce(len_min, op=dist.ReduceOp.MIN)
                    if xvlm_utils.is_main_process():
                        print(f"[dataloader] train_len(rank_local)={int(local_len.item())} max={int(len_max.item())} min={int(len_min.item())}")
            except Exception:
                pass
        
        if xvlm_utils.is_main_process():
            print("@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@")
            print(f"ğŸš€ ä¼˜åŒ–çš„æ•°æ®åŠ è½½å™¨é…ç½®:")
            print(f"  - Workeræ•°é‡: {num_workers}")
            print(f"  - é¢„å–å› å­: {prefetch_factor}")
            print(f"  - æŒä¹…åŒ–Worker: {persistent_workers}")
            print(f"  - æ‰¹å¤„ç†å‡½æ•°: {'ç›‘æ§ç‰ˆä¼˜åŒ–å‡½æ•°' if use_monitoring else 'æ ‡å‡†ä¼˜åŒ–å‡½æ•°'}")
            print(f"  - è®­ç»ƒé›†å†…å­˜å ç”¨: {sys.getsizeof(train_dset)} bytes")
            print(f"  - éªŒè¯é›†å†…å­˜å ç”¨: {sys.getsizeof(val_dset)} bytes")
            print("  âœ“ å¯ç”¨æ™ºèƒ½ç¼“å­˜æœºåˆ¶")
            print("  âœ“ å¯ç”¨åŠ¨æ€å¡«å……ä¼˜åŒ–")
            print("  âœ“ å¯ç”¨å¤šå±‚é”™è¯¯å¤„ç†")
            print("  âœ“ å¯ç”¨å†…å­˜å…±äº«ä¼˜åŒ–")
            print("@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@")
        
        # æ¸…ç†ä¸´æ—¶å˜é‡ï¼Œé‡Šæ”¾å†…å­˜
        del train_dset, val_dset, datasets, samplers
        del train_dl_kwargs, eval_dl_kwargs
        memory_cleanup()
        
        if xvlm_utils.is_main_process():
            print(f'ğŸ’¾ DataLoader åˆ›å»ºå®Œæˆï¼Œå½“å‰æ˜¾å­˜å ç”¨: {torch.cuda.memory_allocated(device) / 1024**3:.2f} GB')

    # è®­ç»ƒå‰æœ€ç»ˆå†…å­˜æ¸…ç†å’ŒçŠ¶æ€æ£€æŸ¥
    memory_cleanup()
    if xvlm_utils.is_main_process():
        print("=" * 60)
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒ - ä» epoch {epoch} å¼€å§‹")
        print(f"ğŸ’¾ è®­ç»ƒå‰æ˜¾å­˜å ç”¨: {torch.cuda.memory_allocated(device) / 1024**3:.2f} GB")
        print(f"ğŸ’¾ è®­ç»ƒå‰æ˜¾å­˜ç¼“å­˜: {torch.cuda.memory_reserved(device) / 1024**3:.2f} GB")
        print("=" * 60)
    
    train(args, model, train_loader, eval_loader, args.epochs, args.output, optim, epoch,config_xvlm=config)
    # eval_cfrf_score, fg_score, coarse_score, ens_score, mid_score, bound = evaluate(model, eval_loader, args,config)


